```{r q4}
fit4<-lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
fit4
fit4nf<-lm(mpg ~ I(wt * 1) + factor(cyl), data = mtcars)
fit4nf
```
## Question Five
Question 5
Consider the following data set
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
Give the hat diagonal for the most influential point
0.2025
0.9946
0.2804
0.2287
```{r q5}
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
df<-data.frame(x,y)
fit5<-lm(y~x,data=df)
summary(fit5)
hatvalues(fit5)
```
## Question Six
```{r q6}
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
df<-data.frame(x,y)
fit6<-lm(y~x,data=df)
dfbeta(fit6)
```
fit<-lm(mpg~factor(cyl)+wt,data=mtcars)
summary(fit)
fitnf<-lm(mpg~cyl+wt,data=mtcars)
summary(fitnf)
fitcf<-lm(mpg~factor(cyl)+wt,data=mtcars)
fitint<-lm(mpg~factor(cyl)*wt,data=mtcars)
summary(fitcf)
summary(fitint)
fit4<-lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
fit4
fit4nf<-lm(mpg ~ I(wt * 1) + factor(cyl), data = mtcars)
fit4nf
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
df<-data.frame(x,y)
fit5<-lm(y~x,data=df)
summary(fit5)
hatvalues(fit5)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
df<-data.frame(x,y)
fit6<-lm(y~x,data=df)
dfbeta(fit6)
library(dplyr)
data(mtcars)
str(mtcars)
#make an am factor column
am<-as.factor(mtcars$am)
mtwide<-mutate(mtcars,amf)
library(dplyr)
data(mtcars)
str(mtcars)
#make an am factor column
am<-as.factor(mtcars$am)
#mtwide<-mutate(mtcars,amf)
str(mtcars)
library(dplyr)
data(mtcars)
str(mtcars)
#make an am factor column
mtcars$am<-as.factor(mtcars$am)
#mtwide<-mutate(mtcars,amf)
str(mtcars)
library(dplyr)
data(mtcars)
str(mtcars)
#make  am a factor column
mtcars$am<-as.factor(mtcars$am)
library(ggplot2)
mtcars$gpm<-100/mtcars$mpg
g<-ggplot(data=mtwide,aes(x=wt,y=gpm,colour=am))+
geom_point()+
geom_smooth(method=lm)+
#facet_wrap(~amf,shrink=FALSE)+
labs(x = "Weight / 1000 lb",y = "Gallons per 100 miles")
g
library(ggplot2)
mtcars$gpm<-100/mtcars$mpg
g<-ggplot(data=mtcars,aes(x=wt,y=gpm,colour=am))+
geom_point()+
geom_smooth(method=lm)+
#facet_wrap(~amf,shrink=FALSE)+
labs(x = "Weight / 1000 lb",y = "Gallons per 100 miles")
g
lm1<-lm(gpm~factor(am),data=mtcars)
lm1
lm(gpm~factor(am)*wt,data=mtcars)
summary(lm(gpm~factor(am)*wt,data=mtcars))
summary(lm(gpm~factor(am)*wt-1,data=mtcars))
summary(lm(gpm~factor(am)+wt-1,data=mtcars))
summary(lm(gpm~factor(am)+wt,data=mtcars))
g2<-ggplot(data=mtcars,aes(x=wt,y=gpm))+
geom_point()+
geom_smooth(method=lm)+
#facet_wrap(~amf,shrink=FALSE)+
labs(x = "Weight / 1000 lb",y = "Gallons per 100 miles")
g2
beta0=-1.5
beta1=3
beta2=-0.5
x1=1
x2=5
P<-1/(1+exp(-beta0+beta1*x1+beta2*x2))
logit<-ln(P/(1-P))
logit
beta0=-1.5
beta1=3
beta2=-0.5
x1=1
x2=5
P<-1/(1+exp(-beta0+beta1*x1+beta2*x2))
logit<-log(P/(1-P))
logit
beta0=-1.5
beta1=3
beta2=-0.5
x1=1
x2=5
P<-1/(1+exp(-beta0+beta1*x1+beta2*x2))
logit<-log(P/(1-P))
logit
odds<-exp(logit)
odds
P
beta0=-1.5
beta1=3
beta2=-0.5
x1=1
x2=5
P<-1/(1+exp(-beta0+beta1*x1+beta2*x2)) # =P(y=1)
logit<-log(P/(1-P))
logit
odds<-exp(logit)
odds
P # =P(y=1)
beta0=-1.5
beta1=3
beta2=-0.5
x1=1
x2=5
P<-1/(1+exp(-(beta0+beta1*x1+beta2*x2))_ # =P(y=1)
logit<-log(P/(1-P))
logit
odds<-exp(logit)
odds
P # =P(y=1)
beta0=-1.5
beta1=3
beta2=-0.5
x1=1
x2=5
P<-1/(1+exp(-(beta0+beta1*x1+beta2*x2))) # =P(y=1)
logit<-log(P/(1-P))
logit
odds<-exp(logit)
odds
P # =P(y=1)
tb<-data.frame("Allocation"=c("Pay costs","Devolved to depts. for CPD","Central Funding"),c(27,33,39))
library(ggplot2)
tb<-data.frame("Category"=c("Pay costs","Devolved to depts. for CPD","Central Funding"),"Allocation"=c(27,33,39))
d<-ggplot(data=tb,
aes(x=Category, y=Allocation,order=Allocation))+
geom_bar(stat="identity")+
#facet_wrap(~variable)+
coord_flip()+
scale_y_continuous(breaks = seq(0, 50, 10))+
theme(axis.text.x = element_text(size=14),
axis.text.y=element_text(size=14))+
labs(y = "% Allocation of total training budget")+
theme(axis.title.x = element_text(size=14,vjust=-.5),
axis.title.y=element_blank())+
theme(legend.text=element_text(size=12),
legend.title = element_blank())+
theme(legend.position=c(.8, .2))
d
d<-ggplot(data=tb,
aes(x=Category, y=Allocation,colour=Allocation, order=Allocation))+
geom_bar(stat="identity")+
#facet_wrap(~variable)+
coord_flip()+
scale_y_continuous(breaks = seq(0, 50, 10))+
theme(axis.text.x = element_text(size=14),
axis.text.y=element_text(size=14))+
labs(y = "% Allocation of total training budget")+
theme(axis.title.x = element_text(size=14,vjust=-.5),
axis.title.y=element_blank())+
theme(legend.text=element_text(size=12),
legend.title = element_blank())+
theme(legend.position=c(.8, .2))
d
d<-ggplot(data=tb,
aes(x=Category, y=Allocation,fill=Allocation, order=Allocation))+
geom_bar(stat="identity")+
#facet_wrap(~variable)+
coord_flip()+
scale_y_continuous(breaks = seq(0, 50, 10))+
theme(axis.text.x = element_text(size=14),
axis.text.y=element_text(size=14))+
labs(y = "% Allocation of total training budget")+
theme(axis.title.x = element_text(size=14,vjust=-.5),
axis.title.y=element_blank())+
theme(legend.text=element_text(size=12),
legend.title = element_blank())+
theme(legend.position=c(.8, .2))
d
d<-ggplot(data=tb,
aes(x=Category, y=Allocation,fill=Allocation, order=Allocation))+
geom_bar(stat="identity")+
#facet_wrap(~variable)+
coord_flip()+
scale_y_continuous(breaks = seq(0, 50, 10))+
theme(axis.text.x = element_text(size=14),
axis.text.y=element_text(size=14))+
labs(y = "% Allocation of total training budget")+
theme(axis.title.x = element_text(size=14,vjust=-.5),
axis.title.y=element_blank())+
# theme(legend.text=element_text(size=12),
legend.title = element_blank())+
#theme(legend.position=c(.8, .2)
)
d
d<-ggplot(data=tb,
aes(x=Category, y=Allocation,fill=Allocation, order=Allocation))+
geom_bar(stat="identity")+
#facet_wrap(~variable)+
coord_flip()+
scale_y_continuous(breaks = seq(0, 50, 10))+
theme(axis.text.x = element_text(size=14),
axis.text.y=element_text(size=14))+
labs(y = "% Allocation of total training budget")+
theme(axis.title.x = element_text(size=14,vjust=-.5),
axis.title.y=element_blank())
# theme(legend.text=element_text(size=12),
# legend.title = element_blank())+
#theme(legend.position=c(.8, .2)
)
d
d<-ggplot(data=tb,
aes(x=Category, y=Allocation,fill=Allocation, order=Allocation))+
geom_bar(stat="identity")+
#facet_wrap(~variable)+
coord_flip()+
scale_y_continuous(breaks = seq(0, 50, 10))+
theme(axis.text.x = element_text(size=14),
axis.text.y=element_text(size=14))+
labs(y = "% Allocation of total training budget")+
theme(axis.title.x = element_text(size=14,vjust=-.5),
axis.title.y=element_blank())
# theme(legend.text=element_text(size=12),
# legend.title = element_blank())+
#theme(legend.position=c(.8, .2))
d
d<-ggplot(data=tb,
aes(x=Category, y=Allocation,fill=Allocation, order=-Allocation))+
geom_bar(stat="identity")+
#facet_wrap(~variable)+
coord_flip()+
scale_y_continuous(breaks = seq(0, 50, 10))+
theme(axis.text.x = element_text(size=14),
axis.text.y=element_text(size=14))+
labs(y = "% Allocation of total training budget")+
theme(axis.title.x = element_text(size=14,vjust=-.5),
axis.title.y=element_blank())
# theme(legend.text=element_text(size=12),
# legend.title = element_blank())+
#theme(legend.position=c(.8, .2))
d
d<-ggplot(data=tb,
aes(x=Category, y=Allocation,fill=Allocation, order=-Allocation))+
geom_bar(stat="identity")+
#facet_wrap(~variable)+
coord_flip()+
scale_y_continuous(breaks = seq(0, 50, 10))+
theme(axis.text.x = element_text(size=18),
axis.text.y=element_text(size=14))+
labs(y = "% Allocation of total training budget")+
theme(axis.title.x = element_text(size=14,vjust=-.5),
axis.title.y=element_blank())
# theme(legend.text=element_text(size=12),
# legend.title = element_blank())+
#theme(legend.position=c(.8, .2))
d
d<-ggplot(data=tb,
aes(x=Category, y=Allocation,fill=Allocation, order=-Allocation))+
geom_bar(stat="identity")+
#facet_wrap(~variable)+
coord_flip()+
scale_y_continuous(breaks = seq(0, 50, 10))+
theme(axis.text.x = element_text(size=18),
axis.text.y=element_text(size=18))+
labs(y = "% Allocation of total training budget")+
theme(axis.title.x = element_text(size=14,vjust=-.5),
axis.title.y=element_blank())
# theme(legend.text=element_text(size=12),
# legend.title = element_blank())+
#theme(legend.position=c(.8, .2))
d
d<-ggplot(data=tb,
aes(x=Category, y=Allocation,fill=Allocation, order=-Allocation))+
geom_bar(stat="identity")+
#facet_wrap(~variable)+
coord_flip()+
scale_y_continuous(breaks = seq(0, 50, 10))+
theme(axis.text.x = element_text(size=18),
axis.text.y=element_text(size=18))+
labs(y = "% Allocation of total training budget")+
theme(axis.title.x = element_text(size=18,vjust=-.5),
axis.title.y=element_blank())
# theme(legend.text=element_text(size=12),
# legend.title = element_blank())+
#theme(legend.position=c(.8, .2))
d
d<-ggplot(data=tb,
aes(x=Category, y=Allocation,fill=Allocation, order=-Allocation))+
geom_bar(stat="identity")+
#facet_wrap(~variable)+
coord_flip()+
scale_y_continuous(breaks = seq(0, 50, 10))+
theme(axis.text.x = element_text(size=18),
axis.text.y=element_text(size=14))+
labs(y = "% Allocation of total training budget")+
theme(axis.title.x = element_text(size=18,vjust=-.5),
axis.title.y=element_blank())
# theme(legend.text=element_text(size=12),
# legend.title = element_blank())+
#theme(legend.position=c(.8, .2))
d
d<-ggplot(data=tb,
aes(x=Category, y=Allocation,fill=Allocation, order=-Allocation))+
geom_bar(stat="identity")+
#facet_wrap(~variable)+
coord_flip()+
scale_y_continuous(breaks = seq(0, 50, 10))+
theme(axis.text.x = element_text(size=18),
axis.text.y=element_text(size=14))+
labs(y = "% Allocation of total training budget")+
theme(axis.title.x = element_text(size=18,vjust=-.5),
axis.title.y=element_blank())+
# theme(legend.text=element_text(size=12),
# legend.title = element_blank())+
theme(legend.position="none")
d
tweets = read.csv("./data/tweets.csv", stringsAsFactors=FALSE)
str(tweets)
setwd("C:/Users/Mike/Rspace/MIT_AE/Unit5")
tweets = read.csv("./data/tweets.csv", stringsAsFactors=FALSE)
str(tweets)
tweets$Negative = as.factor(tweets$Avg <= -1)
table(tweets$Negative)
install.packages("tm")
library(tm)
install.packages("SnowballC")
library(SnowballC)
corpus = Corpus(VectorSource(tweets$Tweet))
corpus
corpus[[1]]
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, PlainTextDocument)
corpus[[1]]
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, removePunctuation)
corpus[[1]]
stopwords("english")[1:10]
stopwords("english")[1:10]
corpus = tm_map(corpus, removeWords, c("apple", stopwords("english")))
corpus[[1]]
corpus = tm_map(corpus, PlainTextDocument)
corpus[[1]]
corpus = tm_map(corpus, stemDocument)
corpus[[1]]
frequencies = DocumentTermMatrix(corpus)
frequencies
inspect(frequencies[1000:1005,505:515])
findFreqTerms(frequencies, lowfreq=20)
sparse = removeSparseTerms(frequencies, 0.995)
sparse
tweetsSparse = as.data.frame(as.matrix(sparse))
colnames(tweetsSparse) = make.names(colnames(tweetsSparse))
tweetsSparse$Negative = tweets$Negative
library(caTools)
set.seed(123)
split = sample.split(tweetsSparse$Negative, SplitRatio = 0.7)
trainSparse = subset(tweetsSparse, split==TRUE)
testSparse = subset(tweetsSparse, split==FALSE)
findFreqTerms(frequencies, lowfreq=100)
library(rpart)
library(rpart.plot)
tweetCART = rpart(Negative ~ ., data=trainSparse, method="class")
prp(tweetCART)
tweetCART = rpart(Negative ~ ., data=trainSparse, method="class")
prp(tweetCART)
predictCART = predict(tweetCART, newdata=testSparse, type="class")
ct<-table(testSparse$Negative, predictCART)
# Compute accuracy
sum(diag(ct))/sum(ct)
library(rpart)
library(rpart.plot)
tweetCART = rpart(Negative ~ ., data=trainSparse, method="class")
prp(tweetCART)
# Evaluate the performance of the model
predictCART = predict(tweetCART, newdata=testSparse, type="class")
ct<-table(testSparse$Negative, predictCART)
ct
# Compute accuracy
sum(diag(ct))/sum(ct)
table(testSparse$Negative)
sum(ct[1,])/sum(ct)
library(randomForest)
set.seed(123)
predictRF = predict(tweetRF, newdata=testSparse)
table(testSparse$Negative, predictRF)
library(randomForest)
set.seed(123)
tweetRF = randomForest(Negative ~ ., data=trainSparse)
# Make predictions:
predictRF = predict(tweetRF, newdata=testSparse)
table(testSparse$Negative, predictRF)
predictRF = predict(tweetRF, newdata=testSparse)
ctRF<-table(testSparse$Negative, predictRF)
# Accuracy:
sum(diag(ctRF))/sum(ctRF)
tweetLog<-glm(Negative~.,family=binomial,data=trainSparse)
predictions = predict(tweetLog, newdata=testSparse, type="response")
tweetLog<-glm(Negative~.,family=binomial,data=trainSparse)
predictions = predict(tweetLog, newdata=testSparse, type="response")
ctLog<-table(testSparse$Negative, predictions)
ctLog
sum(diag(ctLog))/sum(ctLog)
tweetLog<-glm(Negative~.,family=binomial,data=trainSparse)
predictions = predict(tweetLog, newdata=testSparse, type="response")
ctLog<-table(testSparse$Negative, predictions)
ctLog
sum(diag(ctLog))/sum(ctLog)
ctLog<-table(testSparse$Negative, predictions>0.5)
ctLog
sum(diag(ctLog))/sum(ctLog)
emails = read.csv("./data/energy_bids.csv", stringsAsFactors=FALSE)
str(emails)
emails$email[1]
emails$responsive[1]
emails$email[2]
emails$responsive[2]
table(emails$responsive)
library(tm)
# Create corpus
corpus = Corpus(VectorSource(emails$email))
corpus[[1]]
# Pre-process data
corpus = tm_map(corpus, tolower)
# IMPORTANT NOTE: If you are using the latest version of the tm package, you will need to run the following line before continuing (it converts corpus to a Plain Text Document). This is a recent change having to do with the tolower function that occurred after this video was recorded.
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords("english"))
corpus = tm_map(corpus, stemDocument)
# Look at first email
corpus[[1]]
# Video 4
# Create matrix
dtm = DocumentTermMatrix(corpus)
dtm
# Remove sparse terms
dtm = removeSparseTerms(dtm, 0.97)
dtm
# Create data frame
labeledTerms = as.data.frame(as.matrix(dtm))
# Add in the outcome variable
labeledTerms$responsive = emails$responsive
str(labeledTerms)
# Video 5
# Split the data
library(caTools)
set.seed(144)
spl = sample.split(labeledTerms$responsive, 0.7)
train = subset(labeledTerms, spl == TRUE)
test = subset(labeledTerms, spl == FALSE)
# Build a CART model
library(rpart)
library(rpart.plot)
emailCART = rpart(responsive~., data=train, method="class")
prp(emailCART)
# Video 6
# Make predictions on the test set
pred = predict(emailCART, newdata=test)
pred[1:10,]
pred.prob = pred[,2]
# Compute accuracy
table(test$responsive, pred.prob >= 0.5)
(195+25)/(195+25+17+20)
# Baseline model accuracy
table(test$responsive)
215/(215+42)
# Video 7
# ROC curve
library(ROCR)
predROCR = prediction(pred.prob, test$responsive)
perfROCR = performance(predROCR, "tpr", "fpr")
plot(perfROCR, colorize=TRUE)
# Compute AUC
performance(predROCR, "auc")@y.values
length(stopwords("english"))
