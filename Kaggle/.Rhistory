beta2=-0.5
x1=1
x2=5
P<-1/(1+exp(-(beta0+beta1*x1+beta2*x2))) # =P(y=1)
logit<-log(P/(1-P))
logit
odds<-exp(logit)
odds
P # =P(y=1)
tb<-data.frame("Allocation"=c("Pay costs","Devolved to depts. for CPD","Central Funding"),c(27,33,39))
library(ggplot2)
tb<-data.frame("Category"=c("Pay costs","Devolved to depts. for CPD","Central Funding"),"Allocation"=c(27,33,39))
d<-ggplot(data=tb,
aes(x=Category, y=Allocation,order=Allocation))+
geom_bar(stat="identity")+
#facet_wrap(~variable)+
coord_flip()+
scale_y_continuous(breaks = seq(0, 50, 10))+
theme(axis.text.x = element_text(size=14),
axis.text.y=element_text(size=14))+
labs(y = "% Allocation of total training budget")+
theme(axis.title.x = element_text(size=14,vjust=-.5),
axis.title.y=element_blank())+
theme(legend.text=element_text(size=12),
legend.title = element_blank())+
theme(legend.position=c(.8, .2))
d
d<-ggplot(data=tb,
aes(x=Category, y=Allocation,colour=Allocation, order=Allocation))+
geom_bar(stat="identity")+
#facet_wrap(~variable)+
coord_flip()+
scale_y_continuous(breaks = seq(0, 50, 10))+
theme(axis.text.x = element_text(size=14),
axis.text.y=element_text(size=14))+
labs(y = "% Allocation of total training budget")+
theme(axis.title.x = element_text(size=14,vjust=-.5),
axis.title.y=element_blank())+
theme(legend.text=element_text(size=12),
legend.title = element_blank())+
theme(legend.position=c(.8, .2))
d
d<-ggplot(data=tb,
aes(x=Category, y=Allocation,fill=Allocation, order=Allocation))+
geom_bar(stat="identity")+
#facet_wrap(~variable)+
coord_flip()+
scale_y_continuous(breaks = seq(0, 50, 10))+
theme(axis.text.x = element_text(size=14),
axis.text.y=element_text(size=14))+
labs(y = "% Allocation of total training budget")+
theme(axis.title.x = element_text(size=14,vjust=-.5),
axis.title.y=element_blank())+
theme(legend.text=element_text(size=12),
legend.title = element_blank())+
theme(legend.position=c(.8, .2))
d
d<-ggplot(data=tb,
aes(x=Category, y=Allocation,fill=Allocation, order=Allocation))+
geom_bar(stat="identity")+
#facet_wrap(~variable)+
coord_flip()+
scale_y_continuous(breaks = seq(0, 50, 10))+
theme(axis.text.x = element_text(size=14),
axis.text.y=element_text(size=14))+
labs(y = "% Allocation of total training budget")+
theme(axis.title.x = element_text(size=14,vjust=-.5),
axis.title.y=element_blank())+
# theme(legend.text=element_text(size=12),
legend.title = element_blank())+
#theme(legend.position=c(.8, .2)
)
d
d<-ggplot(data=tb,
aes(x=Category, y=Allocation,fill=Allocation, order=Allocation))+
geom_bar(stat="identity")+
#facet_wrap(~variable)+
coord_flip()+
scale_y_continuous(breaks = seq(0, 50, 10))+
theme(axis.text.x = element_text(size=14),
axis.text.y=element_text(size=14))+
labs(y = "% Allocation of total training budget")+
theme(axis.title.x = element_text(size=14,vjust=-.5),
axis.title.y=element_blank())
# theme(legend.text=element_text(size=12),
# legend.title = element_blank())+
#theme(legend.position=c(.8, .2)
)
d
d<-ggplot(data=tb,
aes(x=Category, y=Allocation,fill=Allocation, order=Allocation))+
geom_bar(stat="identity")+
#facet_wrap(~variable)+
coord_flip()+
scale_y_continuous(breaks = seq(0, 50, 10))+
theme(axis.text.x = element_text(size=14),
axis.text.y=element_text(size=14))+
labs(y = "% Allocation of total training budget")+
theme(axis.title.x = element_text(size=14,vjust=-.5),
axis.title.y=element_blank())
# theme(legend.text=element_text(size=12),
# legend.title = element_blank())+
#theme(legend.position=c(.8, .2))
d
d<-ggplot(data=tb,
aes(x=Category, y=Allocation,fill=Allocation, order=-Allocation))+
geom_bar(stat="identity")+
#facet_wrap(~variable)+
coord_flip()+
scale_y_continuous(breaks = seq(0, 50, 10))+
theme(axis.text.x = element_text(size=14),
axis.text.y=element_text(size=14))+
labs(y = "% Allocation of total training budget")+
theme(axis.title.x = element_text(size=14,vjust=-.5),
axis.title.y=element_blank())
# theme(legend.text=element_text(size=12),
# legend.title = element_blank())+
#theme(legend.position=c(.8, .2))
d
d<-ggplot(data=tb,
aes(x=Category, y=Allocation,fill=Allocation, order=-Allocation))+
geom_bar(stat="identity")+
#facet_wrap(~variable)+
coord_flip()+
scale_y_continuous(breaks = seq(0, 50, 10))+
theme(axis.text.x = element_text(size=18),
axis.text.y=element_text(size=14))+
labs(y = "% Allocation of total training budget")+
theme(axis.title.x = element_text(size=14,vjust=-.5),
axis.title.y=element_blank())
# theme(legend.text=element_text(size=12),
# legend.title = element_blank())+
#theme(legend.position=c(.8, .2))
d
d<-ggplot(data=tb,
aes(x=Category, y=Allocation,fill=Allocation, order=-Allocation))+
geom_bar(stat="identity")+
#facet_wrap(~variable)+
coord_flip()+
scale_y_continuous(breaks = seq(0, 50, 10))+
theme(axis.text.x = element_text(size=18),
axis.text.y=element_text(size=18))+
labs(y = "% Allocation of total training budget")+
theme(axis.title.x = element_text(size=14,vjust=-.5),
axis.title.y=element_blank())
# theme(legend.text=element_text(size=12),
# legend.title = element_blank())+
#theme(legend.position=c(.8, .2))
d
d<-ggplot(data=tb,
aes(x=Category, y=Allocation,fill=Allocation, order=-Allocation))+
geom_bar(stat="identity")+
#facet_wrap(~variable)+
coord_flip()+
scale_y_continuous(breaks = seq(0, 50, 10))+
theme(axis.text.x = element_text(size=18),
axis.text.y=element_text(size=18))+
labs(y = "% Allocation of total training budget")+
theme(axis.title.x = element_text(size=18,vjust=-.5),
axis.title.y=element_blank())
# theme(legend.text=element_text(size=12),
# legend.title = element_blank())+
#theme(legend.position=c(.8, .2))
d
d<-ggplot(data=tb,
aes(x=Category, y=Allocation,fill=Allocation, order=-Allocation))+
geom_bar(stat="identity")+
#facet_wrap(~variable)+
coord_flip()+
scale_y_continuous(breaks = seq(0, 50, 10))+
theme(axis.text.x = element_text(size=18),
axis.text.y=element_text(size=14))+
labs(y = "% Allocation of total training budget")+
theme(axis.title.x = element_text(size=18,vjust=-.5),
axis.title.y=element_blank())
# theme(legend.text=element_text(size=12),
# legend.title = element_blank())+
#theme(legend.position=c(.8, .2))
d
d<-ggplot(data=tb,
aes(x=Category, y=Allocation,fill=Allocation, order=-Allocation))+
geom_bar(stat="identity")+
#facet_wrap(~variable)+
coord_flip()+
scale_y_continuous(breaks = seq(0, 50, 10))+
theme(axis.text.x = element_text(size=18),
axis.text.y=element_text(size=14))+
labs(y = "% Allocation of total training budget")+
theme(axis.title.x = element_text(size=18,vjust=-.5),
axis.title.y=element_blank())+
# theme(legend.text=element_text(size=12),
# legend.title = element_blank())+
theme(legend.position="none")
d
source('C:/Users/Mike/Rspace/RECM/thermalMass.r', echo=TRUE)
library(swirl)
swirl()
var(rpois(1000,50))
nxt()
head(hits)
class(hits[,"date'])
)
class(hits[,"date"])
as.integer(head(hits[,"data"]))
as.integer(head(hits[,"date"]))
mdl<-glm(visits~date,family=poisson,data=hits)
summary(mdl)
exp(confint(mdl,"date"))
which.max(hits[,"visits"])
hits[704,]
lambda<-mdl$fitted.values[704]
qpois(0.95,lambda)
mdl2<-offset=log(visits+1)
mdl2<-log(visits+1)
mdl2<-glm$offset
?
swirl()
library(swirl)
swirl()
swirl()
# accuracy - 0.8278228
rm(list=ls())
# Read in data
train = read.csv("./data/eBayiPadTrain.csv",stringsAsFactors=FALSE,na.strings=c("Unknown",""))
test = read.csv("./data/eBayiPadTest.csv", stringsAsFactors=FALSE,na.strings=c("Unknown",""))
attach(train)
str(train)
train=subset(train,!is.na(biddable))
str(train)
train=subset(train,!is.na(startprice))
str(train)
train=subset(train,!is.na(condition))
str(train)
train=subset(train,!is.na(storage))
str(train)
train=subset(train,!is.na(productline))
str(train)
# train=data.frame(biddable,startprice,condition,storage,productline,sold)
# train=na.omit(train)
# str(train)
mean(train$sold)  # is <0.5 - so most are not sol
## LOGISTIC REGRESSION MODEL
# keep only significant variables
modelLog<-glm(sold~biddable+startprice+condition+storage+productline,family=binomial,data=train)
summary(modelLog)
# 1.2 What is the accuracy of the model on the traintest set?
# Use a threshold of 0.5.
predictLog = predict(modelLog,newdata=train)
max(predictLog)
ct<-table(train$sold, predictLog >= 0.5)
ct
(sum(diag(ct)))/sum(ct)
# 1.3 What is the baseline accuracy for the testing set?
# = accuracy of the prediction always that iPad not sold.
sum(ct[1,])/sum(ct)
# What is the area-under-the-curve (AUC) for this model on the train set?
# ROC curve
library(ROCR)
predLog = prediction(predictLog, train$sold)
as.numeric(performance(predLog, "auc")@y.values)
perfLog = performance(predLog, "tpr", "fpr")
plot(perfLog)
# And then make predictions on the test set:
PredTest = predict(modelLog, newdata=test, type="response")
# We can't compute the accuracy or AUC on the test set ourselves, since we don't have the dependent variable on the test set (you can compute it on the training set though!).
# However, you can submit the file on Kaggle to see how well the model performs. You can make up to 5 submissions per day, so don't hesitate to just upload a solution to see how you did.
# Let's prepare a submission file for Kaggle (for more about this, see the "Evaluation" page on the competition site):
setwd("C:/Users/Mike/Rspace/MIT_AE/Kaggle")
# accuracy - 0.8278228
rm(list=ls())
# Read in data
train = read.csv("./data/eBayiPadTrain.csv",stringsAsFactors=FALSE,na.strings=c("Unknown",""))
test = read.csv("./data/eBayiPadTest.csv", stringsAsFactors=FALSE,na.strings=c("Unknown",""))
attach(train)
str(train)
train=subset(train,!is.na(biddable))
str(train)
train=subset(train,!is.na(startprice))
str(train)
train=subset(train,!is.na(condition))
str(train)
train=subset(train,!is.na(storage))
str(train)
train=subset(train,!is.na(productline))
str(train)
# train=data.frame(biddable,startprice,condition,storage,productline,sold)
# train=na.omit(train)
# str(train)
mean(train$sold)  # is <0.5 - so most are not sol
## LOGISTIC REGRESSION MODEL
# keep only significant variables
modelLog<-glm(sold~biddable+startprice+condition+storage+productline,family=binomial,data=train)
summary(modelLog)
# 1.2 What is the accuracy of the model on the traintest set?
# Use a threshold of 0.5.
predictLog = predict(modelLog,newdata=train)
max(predictLog)
ct<-table(train$sold, predictLog >= 0.5)
ct
(sum(diag(ct)))/sum(ct)
# 1.3 What is the baseline accuracy for the testing set?
# = accuracy of the prediction always that iPad not sold.
sum(ct[1,])/sum(ct)
# What is the area-under-the-curve (AUC) for this model on the train set?
# ROC curve
library(ROCR)
predLog = prediction(predictLog, train$sold)
as.numeric(performance(predLog, "auc")@y.values)
perfLog = performance(predLog, "tpr", "fpr")
plot(perfLog)
# And then make predictions on the test set:
PredTest = predict(modelLog, newdata=test, type="response")
# We can't compute the accuracy or AUC on the test set ourselves, since we don't have the dependent variable on the test set (you can compute it on the training set though!).
# However, you can submit the file on Kaggle to see how well the model performs. You can make up to 5 submissions per day, so don't hesitate to just upload a solution to see how you did.
# Let's prepare a submission file for Kaggle (for more about this, see the "Evaluation" page on the competition site):
str(PredTest)
head(PredTest,30)
fix(train)
PredTest = predict(modelLog, newdata=test, type="response")
# We can't compute the accuracy or AUC on the test set ourselves, since we don't have the dependent variable on the test set (you can compute it on the training set though!).
# However, you can submit the file on Kaggle to see how well the model performs. You can make up to 5 submissions per day, so don't hesitate to just upload a solution to see how you did.
# Let's prepare a submission file for Kaggle (for more about this, see the "Evaluation" page on the competition site):
library(Hmisc)
MySubmission2b = data.frame(UniqueID = test$UniqueID, Probability1 = PredTest)
fix(MySubmission2b)
fix(test)
## KAGGLE COMPETITION
## S2a - Logistic regression - significant variables only, nas removed only from these.
# biddable+startprice+condition+cellular+carrier+color+storage+productline
# train AUC - 0.8626658
# test AUC  - 0.83625
# accuracy - 0.8278228
rm(list=ls())
# Read in data
train = read.csv("./data/eBayiPadTrain.csv",stringsAsFactors=FALSE,na.strings=c("Unknown",""))
test = read.csv("./data/eBayiPadTest.csv", stringsAsFactors=FALSE,na.strings=c("Unknown",""))
attach(train)
str(train)
train=subset(train,!is.na(biddable))
str(train)
train=subset(train,!is.na(startprice))
str(train)
train=subset(train,!is.na(condition))
str(train)
train=subset(train,!is.na(storage))
str(train)
train=subset(train,!is.na(productline))
str(train)
# train=data.frame(biddable,startprice,condition,storage,productline,sold)
# train=na.omit(train)
# str(train)
mean(train$sold)  # is <0.5 - so most are not sol
## LOGISTIC REGRESSION MODEL
# keep only significant variables
modelLog<-glm(sold~biddable+startprice+condition+storage,family=binomial,data=train)
summary(modelLog)
# 1.2 What is the accuracy of the model on the traintest set?
# Use a threshold of 0.5.
predictLog = predict(modelLog,newdata=train)
max(predictLog)
ct<-table(train$sold, predictLog >= 0.5)
ct
(sum(diag(ct)))/sum(ct)
# 1.3 What is the baseline accuracy for the testing set?
# = accuracy of the prediction always that iPad not sold.
sum(ct[1,])/sum(ct)
# What is the area-under-the-curve (AUC) for this model on the train set?
# ROC curve
library(ROCR)
predLog = prediction(predictLog, train$sold)
as.numeric(performance(predLog, "auc")@y.values)
summary(PredTest)
## KAGGLE COMPETITION
## S2a - Logistic regression - significant variables only, nas removed only from these.
# biddable+startprice+condition+cellular+carrier+color+storage+productline
# train AUC - 0.8626658
# test AUC  - 0.83625
# accuracy - 0.8278228
rm(list=ls())
# Read in data
train = read.csv("./data/eBayiPadTrain.csv",stringsAsFactors=FALSE,na.strings=c("Unknown",""))
test = read.csv("./data/eBayiPadTest.csv", stringsAsFactors=FALSE,na.strings=c("Unknown",""))
attach(train)
str(train)
train=subset(train,!is.na(biddable))
str(train)
train=subset(train,!is.na(startprice))
str(train)
train=subset(train,!is.na(condition))
str(train)
train=subset(train,!is.na(storage))
str(train)
train=subset(train,!is.na(productline))
str(train)
# train=data.frame(biddable,startprice,condition,storage,productline,sold)
# train=na.omit(train)
# str(train)
mean(train$sold)  # is <0.5 - so most are not sol
## LOGISTIC REGRESSION MODEL
# keep only significant variables
modelLog<-glm(sold~biddable+startprice+condition+storage+productline,family=binomial,data=train)
summary(modelLog)
# 1.2 What is the accuracy of the model on the traintest set?
# Use a threshold of 0.5.
predictLog = predict(modelLog,newdata=train)
max(predictLog)
ct<-table(train$sold, predictLog >= 0.5)
ct
(sum(diag(ct)))/sum(ct)
# 1.3 What is the baseline accuracy for the testing set?
# = accuracy of the prediction always that iPad not sold.
sum(ct[1,])/sum(ct)
# What is the area-under-the-curve (AUC) for this model on the train set?
# ROC curve
library(ROCR)
predLog = prediction(predictLog, train$sold)
as.numeric(performance(predLog, "auc")@y.values)
perfLog = performance(predLog, "tpr", "fpr")
plot(perfLog)
# And then make predictions on the test set:
PredTest = predict(modelLog, newdata=test, type="response")
# We can't compute the accuracy or AUC on the test set ourselves, since we don't have the dependent variable on the test set (you can compute it on the training set though!).
# However, you can submit the file on Kaggle to see how well the model performs. You can make up to 5 submissions per day, so don't hesitate to just upload a solution to see how you did.
# Let's prepare a submission file for Kaggle (for more about this, see the "Evaluation" page on the competition site):
library(Hmisc)
MySubmission2b = data.frame(UniqueID = test$UniqueID, Probability1 = PredTest)
MySubmission2b$Probability1 <- as.numeric(with(MySubmission2b, impute(Probability1, 0.5)))
write.csv(MySubmission2b, "./submissions/SubmissionSimpleLog2b.csv", row.names=FALSE)
# You should upload the submission "SubmissionSimpleLog.csv" on the Kaggle website to use this as a submission to the competition
summary(PredTest)
testimp<-with(test,impute(productline, "mode")
)
fix(testimp)
fix(test)
class(test)
class(testimp)
str(testimp)
test$productline<-as.character(with(test,impute(productline, "mode")))
fix(test)
table(test$productline)
test$productline<-as.character(with(test,impute(productline, "iPad 2")))
table(test$productline)
## KAGGLE COMPETITION
## S2a - Logistic regression - significant variables only, nas removed only from these.
# biddable+startprice+condition+cellular+carrier+color+storage+productline
# train AUC - 0.8626658
# test AUC  - 0.83625
# accuracy - 0.8278228
rm(list=ls())
# Read in data
train = read.csv("./data/eBayiPadTrain.csv",stringsAsFactors=FALSE,na.strings=c("Unknown",""))
test = read.csv("./data/eBayiPadTest.csv", stringsAsFactors=FALSE,na.strings=c("Unknown",""))
attach(train)
str(train)
train=subset(train,!is.na(biddable))
str(train)
train=subset(train,!is.na(startprice))
str(train)
train=subset(train,!is.na(condition))
str(train)
train=subset(train,!is.na(storage))
str(train)
train=subset(train,!is.na(productline))
str(train)
# train=data.frame(biddable,startprice,condition,storage,productline,sold)
# train=na.omit(train)
# str(train)
mean(train$sold)  # is <0.5 - so most are not sol
## LOGISTIC REGRESSION MODEL
# keep only significant variables
modelLog<-glm(sold~biddable+startprice+condition+storage+productline,family=binomial,data=train)
summary(modelLog)
# 1.2 What is the accuracy of the model on the traintest set?
# Use a threshold of 0.5.
predictLog = predict(modelLog,newdata=train)
max(predictLog)
ct<-table(train$sold, predictLog >= 0.5)
ct
(sum(diag(ct)))/sum(ct)
# 1.3 What is the baseline accuracy for the testing set?
# = accuracy of the prediction always that iPad not sold.
sum(ct[1,])/sum(ct)
# What is the area-under-the-curve (AUC) for this model on the train set?
# ROC curve
library(ROCR)
predLog = prediction(predictLog, train$sold)
as.numeric(performance(predLog, "auc")@y.values)
perfLog = performance(predLog, "tpr", "fpr")
plot(perfLog)
# And then make predictions on the test set:
library(Hmisc)
test$productline<-as.character(with(test,impute(productline, "iPad 2")))
PredTest = predict(modelLog, newdata=test, type="response")
# We can't compute the accuracy or AUC on the test set ourselves, since we don't have the dependent variable on the test set (you can compute it on the training set though!).
# However, you can submit the file on Kaggle to see how well the model performs. You can make up to 5 submissions per day, so don't hesitate to just upload a solution to see how you did.
# Let's prepare a submission file for Kaggle (for more about this, see the "Evaluation" page on the competition site):
table(test$productline)
MySubmission2b = data.frame(UniqueID = test$UniqueID, Probability1 = PredTest)
fix(MySubmission2b)
summary(MySubmission2b)
fix(MySubmission2b)
fix(test)
summary(test)
table(test$storage,test$productline)
test$productline<-as.character(with(test,impute(productline, "iPad 2")))
test$storage<-as.numeric(with(test,impute(storage, 16)))
PredTest = predict(modelLog, newdata=test, type="response")
summary(test)
PredTest = predict(modelLog, newdata=test, type="response")
MySubmission2b = data.frame(UniqueID = test$UniqueID, Probability1 = PredTest)
fix(MySubmission2b)
write.csv(MySubmission2b, "./submissions/SubmissionSimpleLog2bimpute.csv", row.names=FALSE)
