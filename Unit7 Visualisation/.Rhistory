wsAdj<-function(height,hVector,wsVector){
hlog<-log(hVector/hVector[1])
wslog<-log(wsVector/wsVector[1])
fit<-lm(wslog~-1+hlog)
wsVector[1]*(height/hVector[1])^fit[1]
}
wsAdj(15,hv,ws)
hlog<-log(hv/hv[1])
wslog<-log(ws/ws[1])
fit<-lm(wslog~-1+hlog)
fit[1]
class(fit[1])
fit[[1]]
class(fir[[1]])
class(fit[[1]])
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
selectedid <-as.vector(windSpeeds[windSpeeds$id==24,])
wsVector<-selectedid[4:6]
wsVector
class(wsVector)
class(selectedid[[4:6]])
selectedid[[4:6]]
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
fit
fit[[1]]
fit[[1]]*2
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
wsVector <-as.vector(windSpeeds[windSpeeds$id==id,4:6])
id=45
wsVector <-as.vector(windSpeeds[windSpeeds$id==id,4:6])
class(wsVector)
class(as.vector(wsVector))
class (c(10,25,45))
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
?clearShapes
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
rm(list=ls())
df = data.frame(Lat = 1:10, Long = rnorm(10))
leaflet(df) %>% addCircles()
df = data.frame(Lat = 1:10, Long = rnorm(10))
leaflet(df) %>% addTiles() %>% addCircles()
df = data.frame(Lat = 1:10, Long = rnorm(10))
leaflet() %>% addTiles() %>% addCircles(data=df)
?navbarPage
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project')
devtools::install_github('muschellij2/slidify')
library(slidify)
library("stringr", lib.loc="\\\\cam-stf-fs1/users/michael.hunt/my documents/R/win-library/3.2")
install.packages(c("car", "CORElearn", "dplyr", "jsonlite", "quantreg", "raster", "sp", "tidyr", "xml2"))
# install slidify
install_github('ramnathv/slidify')
install_github('ramnathv/slidifyLibraries')
install.packages("devtools")
library(devtools)
install.packages("devtools")
# install slidify
install_github('ramnathv/slidify')
install_github('ramnathv/slidifyLibraries')
install_github('ramnathv/slidify')
library(devtools)
install.packages("devtools")
library(devtools)
library(stringr)
install.packages("devtools")
library(devtools)
require(devtools)
install.packages(c('devtools','xml2'))
library(devtools)
install.packages("Rtools")
library(slidify)
install_github('ramnathv/slidify')
install_github('ramnathv/slidifyLibraries')
library(slidify)
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project/Shiny')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project/Shiny')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project/Shiny')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project/Shiny')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project/Shiny')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project/Shiny')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project/Shiny')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project/Shiny')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project/Shiny')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project/Shiny')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project/Shiny')
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project/Shiny')
cat('<iframe> m</iframe>')
saveWidget(m, 'cornwall.html')
?cat
library(slidify)
setwd("H:/Rspace/JHU_Data_Science/JHU_DDP/Project/Shiny")
shiny::runApp()
setwd("H:/CAQU")
#install and load required packages
CAQU_setup<-function(){
#install packages required
install.packages("ggplot2")
install.packages("dplyr")
install.packages("reshape2")
#load them
library("ggplot2")
library("dplyr")
library("reshape2")
}
# Plot diurnal means of TP, PM10, PM2.5, PM1 on same axes
#TNO2245Data_1429877310388
plotDiurnalMeans
plotDiurnalMeans<-function(id,directory){
#Read in data, rename columns and delete empty columns
d<-read.csv( paste(directory,"/",id,".csv",sep="") )
colnames(d)<-c("TimeStamp","TP","PM10","PM2.5","PM1","T","H","WS","WD","GPS")
d<-subset(d,select=-c(T,H,GPS))
#retain only values where all PM data are valid
dg<-subset(d,PM10 > 0 & PM2.5 > 0 & PM1 > 0 & PM10>=PM2.5 & PM2.5>=PM1 & TP<100)
#create vectors of dates, days, months and times of day at which measurements are taken
#Convert TimeStamp to POSIXlt format
dg$TimeStamp<-as.POSIXlt(strptime(dg$TimeStamp, format= "%d/%m/%Y %T"))
dates<-with(dg,paste(TimeStamp$year+1900,"-",TimeStamp$mon,"-",TimeStamp$mday,sep=""))
dates<-as.Date(dates)
days<-with(dg,TimeStamp$wday)
months<-with(dg,TimeStamp$mon)
times<-with(dg,paste(TimeStamp$hour,":",TimeStamp$min,sep=""))
#add these vectors to the data frame
dg<-cbind(dg,dates,days,months,times)
#find the means at each time of day
s.times<-split(dg,dg$times)
s2<-sapply(s.times, function(x) {colMeans(x[, c("TP", "PM10", "PM2.5","PM1")])})
s3<-t(s2)
s4<-data.frame(s3)
s5<-data.frame(c(seq(0,23.75,.25)),s4)
colnames(s5)[1]<-"Time"
ggplot(melt(s5,id.vars="Time"),aes(x=Time,y=value,col=variable))+
scale_x_continuous(limits=c(0,24),breaks=c(0,4,8,12,16,20,24))+
geom_line()+
scale_y_continuous(limits = c(0, NA))+
#facet_wrap(~variable,scales="free_y")+
ylab( bquote(mu~g~m^{-3}))+
ggtitle("CAQU data")
#summary(dg)
}
#install and load required packages
CAQU_setup<-function(){
#install packages required
install.packages("ggplot2")
install.packages("dplyr")
install.packages("reshape2")
#load them
library("ggplot2")
library("dplyr")
library("reshape2")
}
# Plot diurnal means of TP, PM10, PM2.5, PM1 on same axes
#TNO2245Data_1429877310388
plotDiurnalMeans
plotDiurnalMeans<-function(id,directory){
#Read in data, rename columns and delete empty columns
d<-read.csv( paste(directory,"/",id,".csv",sep="") )
colnames(d)<-c("TimeStamp","TP","PM10","PM2.5","PM1","T","H","WS","WD","GPS")
d<-subset(d,select=-c(T,H,GPS))
#retain only values where all PM data are valid
dg<-subset(d,PM10 > 0 & PM2.5 > 0 & PM1 > 0 & PM10>=PM2.5 & PM2.5>=PM1 & TP<100)
#create vectors of dates, days, months and times of day at which measurements are taken
#Convert TimeStamp to POSIXlt format
dg$TimeStamp<-as.POSIXlt(strptime(dg$TimeStamp, format= "%d/%m/%Y %T"))
dates<-with(dg,paste(TimeStamp$year+1900,"-",TimeStamp$mon,"-",TimeStamp$mday,sep=""))
dates<-as.Date(dates)
days<-with(dg,TimeStamp$wday)
months<-with(dg,TimeStamp$mon)
times<-with(dg,paste(TimeStamp$hour,":",TimeStamp$min,sep=""))
#add these vectors to the data frame
dg<-cbind(dg,dates,days,months,times)
#find the means at each time of day
s.times<-split(dg,dg$times)
s2<-sapply(s.times, function(x) {colMeans(x[, c("TP", "PM10", "PM2.5","PM1")])})
s3<-t(s2)
s4<-data.frame(s3)
s5<-data.frame(c(seq(0,23.75,.25)),s4)
colnames(s5)[1]<-"Time"
g<-ggplot(melt(s5,id.vars="Time"),aes(x=Time,y=value,col=variable))+
scale_x_continuous(limits=c(0,24),breaks=c(0,4,8,12,16,20,24))+
geom_line()+
scale_y_continuous(limits = c(0, NA))+
#facet_wrap(~variable,scales="free_y")+
ylab( bquote(mu~g~m^{-3}))+
ggtitle("CAQU data")
#summary(dg)
g
setwd("H:/Rspace/MIT_AE/Unit7 Visualisation")
## ELECTION FORECASTING REVISITED
# load packages
library(ggplot2)
library(maps)
library(ggmap)
# Load the map of the US
statesMap = map_data("state")
## 1. DRAWING A MAP OF THE US
# 1.1 How many groups are there?
str(statesMap)
length(unique(statesMap$group))
# 1.2
ggplot(statesMap, aes(x = long, y = lat, group = group)) + geom_polygon(fill = "white", color = "black")
## 2. COLORING THE STATES BY PREDICTIONS
# read in data
polling=read.csv("./data/PollingImputed.csv")
str(polling)
# split data into Train (up to 2008) and Test sets
Train=subset(polling,Year<=2008 & Year >= 2004)
Test=subset(polling,Year>=2012)
# create a logistic regression model
mod2 = glm(Republican~SurveyUSA+DiffCount, data=Train, family="binomial")
# make predictions on the test set
TestPrediction = predict(mod2, newdata=Test, type="response")
# TestPrediction gives the predicted probabilities for each state
# create a vector of Republican/Democrat predictions
TestPredictionBinary = as.numeric(TestPrediction > 0.5)
# put the predictions and state labels in a data.frame so that we can use ggplot:
predictionDataFrame = data.frame(TestPrediction, TestPredictionBinary, Test$State)
# How many states are predicted to be Republican for 2012?
nrow(predictionDataFrame[TestPredictionBinary==1,])
# average predicted probability for 2012
mean(predictionDataFrame$TestPrediction)
# 2.2
# Now, we need to merge "predictionDataFrame" with the map data "statesMap",
# like we did in lecture. Before doing so, we need to convert the Test.State
# variable to lowercase, so that it matches the region variable in statesMap.
predictionDataFrame$region = tolower(predictionDataFrame$Test.State)
# Now, merge the two data frames
predictionMap = merge(statesMap, predictionDataFrame, by = "region")
# Lastly, we need to make sure the observations are in order so that the map
# is drawn properly:
predictionMap = predictionMap[order(predictionMap$order),]
str(predictionMap)
str(statesMap)
# 2.4
# color the states according to our binary predictions
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPredictionBinary))+
geom_polygon(color = "black")
# 2.5
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPredictionBinary))+
geom_polygon(color = "black") +
scale_fill_gradient(low = "blue", high = "red", guide = "legend", breaks= c(0,1), labels = c("Democrat", "Republican"), name = "Prediction 2012")
# plot the probabilities instead of the binary predictions
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPrediction))+
geom_polygon(color = "black") +
scale_fill_gradient(low = "blue", high = "red", guide = "legend", breaks= c(0,1), labels = c("Democrat", "Republican"), name = "Prediction 2012")
## 3.UNDERSTANDING THE PREDICTIONS
# 3.2
# What was our predicted probability for the state of Florida?
predictionDataFrame # look at row containing Florida
library(ggplot2)
library(maps)
library(ggmap)
statesMap = map_data("state")
## 1. DRAWING A MAP OF THE US
# 1.1 How many groups are there?
str(statesMap)
length(unique(statesMap$group))
# 1.2
ggplot(statesMap, aes(x = long, y = lat, group = group)) + geom_polygon(fill = "white", color = "black")
## 2. COLORING THE STATES BY PREDICTIONS
polling=read.csv("./data/PollingImputed.csv")
str(polling)
# split data into Train (up to 2008) and Test sets
Train=subset(polling,Year<=2008 & Year >= 2004)
Test=subset(polling,Year>=2012)
# create a logistic regression model
mod2 = glm(Republican~SurveyUSA+DiffCount, data=Train, family="binomial")
# make predictions on the test set
TestPrediction = predict(mod2, newdata=Test, type="response")
# TestPrediction gives the predicted probabilities for each state
# create a vector of Republican/Democrat predictions
TestPredictionBinary = as.numeric(TestPrediction > 0.5)
# put the predictions and state labels in a data.frame so that we can use ggplot:
predictionDataFrame = data.frame(TestPrediction, TestPredictionBinary, Test$State)
# How many states are predicted to be Republican for 2012?
nrow(predictionDataFrame[TestPredictionBinary==1,])
# average predicted probability for 2012
mean(predictionDataFrame$TestPrediction)
# 2.2
# Now, we need to merge "predictionDataFrame" with the map data "statesMap",
# like we did in lecture. Before doing so, we need to convert the Test.State
# variable to lowercase, so that it matches the region variable in statesMap.
predictionDataFrame$region = tolower(predictionDataFrame$Test.State)
# Now, merge the two data frames
predictionMap = merge(statesMap, predictionDataFrame, by = "region")
# Lastly, we need to make sure the observations are in order so that the map
# is drawn properly:
predictionMap = predictionMap[order(predictionMap$order),]
str(predictionMap)
str(statesMap)
# 2.4
# color the states according to our binary predictions
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPredictionBinary))+
geom_polygon(color = "black")
# 2.5
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPredictionBinary))+
geom_polygon(color = "black") +
scale_fill_gradient(low = "blue", high = "red", guide = "legend", breaks= c(0,1), labels = c("Democrat", "Republican"), name = "Prediction 2012")
# plot the probabilities instead of the binary predictions
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPrediction))+
geom_polygon(color = "black") +
scale_fill_gradient(low = "blue", high = "red", guide = "legend", breaks= c(0,1), labels = c("Democrat", "Republican"), name = "Prediction 2012")
predict
?predict
polling=read.csv("./data/PollingImputed.csv")
str(polling)
setwd("H:/Rspace/MIT_AE/Unit7 Visualisation")
polling=read.csv("./data/PollingImputed.csv")
str(polling)
polling=read.csv("./data/PollingImputed.csv")
str(polling)
# split data into Train (up to 2008) and Test sets
Train=subset(polling,Year<=2008 & Year >= 2004)
Test=subset(polling,Year>=2012)
# create a logistic regression model
mod2 = glm(Republican~SurveyUSA+DiffCount, data=Train, family="binomial")
# make predictions on the test set
TestPrediction = predict(mod2, newdata=Test, type="response")
# TestPrediction gives the predicted probabilities for each state
# create a vector of Republican/Democrat predictions
TestPredictionBinary = as.numeric(TestPrediction > 0.5)
# put the predictions and state labels in a data.frame so that we can use ggplot:
predictionDataFrame = data.frame(TestPrediction, TestPredictionBinary, Test$State)
# How many states are predicted to be Republican for 2012?
nrow(predictionDataFrame[TestPredictionBinary==1,])
# average predicted probability for 2012
mean(predictionDataFrame$TestPrediction)
# 2.2
# Now, we need to merge "predictionDataFrame" with the map data "statesMap",
# like we did in lecture. Before doing so, we need to convert the Test.State
# variable to lowercase, so that it matches the region variable in statesMap.
predictionDataFrame$region = tolower(predictionDataFrame$Test.State)
# Now, merge the two data frames
predictionMap = merge(statesMap, predictionDataFrame, by = "region")
# Lastly, we need to make sure the observations are in order so that the map
# is drawn properly:
predictionMap = predictionMap[order(predictionMap$order),]
str(predictionMap)
str(statesMap)
# 2.4
# color the states according to our binary predictions
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPredictionBinary))+
geom_polygon(color = "black")
# 2.5
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPredictionBinary))+
geom_polygon(color = "black") +
scale_fill_gradient(low = "blue", high = "red", guide = "legend", breaks= c(0,1), labels = c("Democrat", "Republican"), name = "Prediction 2012")
# plot the probabilities instead of the binary predictions
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPrediction))+
geom_polygon(color = "black") +
scale_fill_gradient(low = "blue", high = "red", guide = "legend", breaks= c(0,1), labels = c("Democrat", "Republican"), name = "Prediction 2012")
## 3.UNDERSTANDING THE PREDICTIONS
# 3.2
# What was our predicted probability for the state of Florida?
predictionDataFrame # look at row containing Florida
## ELECTION FORECASTING REVISITED
# load packages
library(ggplot2)
library(maps)
library(ggmap)
# Load the map of the US
statesMap = map_data("state")
## 1. DRAWING A MAP OF THE US
# 1.1 How many groups are there?
str(statesMap)
length(unique(statesMap$group))
# 1.2
ggplot(statesMap, aes(x = long, y = lat, group = group)) + geom_polygon(fill = "white", color = "black")
## 2. COLORING THE STATES BY PREDICTIONS
# read in data
polling=read.csv("./data/PollingImputed.csv")
str(polling)
# split data into Train (up to 2008) and Test sets
Train=subset(polling,Year<=2008 & Year >= 2004)
Test=subset(polling,Year>=2012)
# create a logistic regression model
mod2 = glm(Republican~SurveyUSA+DiffCount, data=Train, family="binomial")
# make predictions on the test set
TestPrediction = predict(mod2, newdata=Test, type="response")
# TestPrediction gives the predicted probabilities for each state
# create a vector of Republican/Democrat predictions
TestPredictionBinary = as.numeric(TestPrediction > 0.5)
# put the predictions and state labels in a data.frame so that we can use ggplot:
predictionDataFrame = data.frame(TestPrediction, TestPredictionBinary, Test$State)
# How many states are predicted to be Republican for 2012?
nrow(predictionDataFrame[TestPredictionBinary==1,])
# average predicted probability for 2012
mean(predictionDataFrame$TestPrediction)
# 2.2
# Now, we need to merge "predictionDataFrame" with the map data "statesMap",
# like we did in lecture. Before doing so, we need to convert the Test.State
# variable to lowercase, so that it matches the region variable in statesMap.
predictionDataFrame$region = tolower(predictionDataFrame$Test.State)
# Now, merge the two data frames
predictionMap = merge(statesMap, predictionDataFrame, by = "region")
# Lastly, we need to make sure the observations are in order so that the map
# is drawn properly:
predictionMap = predictionMap[order(predictionMap$order),]
str(predictionMap)
str(statesMap)
# 2.4
# color the states according to our binary predictions
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPredictionBinary))+
geom_polygon(color = "black")
# 2.5
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPredictionBinary))+
geom_polygon(color = "black") +
scale_fill_gradient(low = "blue", high = "red", guide = "legend", breaks= c(0,1), labels = c("Democrat", "Republican"), name = "Prediction 2012")
# plot the probabilities instead of the binary predictions
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPrediction))+
geom_polygon(color = "black") +
scale_fill_gradient(low = "blue", high = "red", guide = "legend", breaks= c(0,1), labels = c("Democrat", "Republican"), name = "Prediction 2012")
## 3.UNDERSTANDING THE PREDICTIONS
# 3.2
# What was our predicted probability for the state of Florida?
predictionDataFrame # look at row containing Florida
shiny::runApp('H:/Rspace/JHU_Data_Science/JHU_DDP/Project/Shiny')
setwd("H:/Rspace/MIT_AE/Unit7 Visualisation")
packages
library(ggplot2)
library(maps)
library(ggmap)
# Load the map of the US
statesMap = map_data("state")
## 1. DRAWING A MAP OF THE US
# 1.1 How many groups are there?
str(statesMap)
length(unique(statesMap$group))
# 1.2
ggplot(statesMap, aes(x = long, y = lat, group = group)) + geom_polygon(fill = "white", color = "black")
## 2. COLORING THE STATES BY PREDICTIONS
# read in data
polling=read.csv("./data/PollingImputed.csv")
str(polling)
# split data into Train (up to 2008) and Test sets
Train=subset(polling,Year<=2008 & Year >= 2004)
Test=subset(polling,Year>=2012)
# create a logistic regression model
mod2 = glm(Republican~SurveyUSA+DiffCount, data=Train, family="binomial")
# make predictions on the test set
TestPrediction = predict(mod2, newdata=Test, type="response")
# TestPrediction gives the predicted probabilities for each state
# create a vector of Republican/Democrat predictions
TestPredictionBinary = as.numeric(TestPrediction > 0.5)
# put the predictions and state labels in a data.frame so that we can use ggplot:
predictionDataFrame = data.frame(TestPrediction, TestPredictionBinary, Test$State)
# How many states are predicted to be Republican for 2012?
nrow(predictionDataFrame[TestPredictionBinary==1,])
# average predicted probability for 2012
mean(predictionDataFrame$TestPrediction)
# 2.2
# Now, we need to merge "predictionDataFrame" with the map data "statesMap",
# like we did in lecture. Before doing so, we need to convert the Test.State
# variable to lowercase, so that it matches the region variable in statesMap.
predictionDataFrame$region = tolower(predictionDataFrame$Test.State)
# Now, merge the two data frames
predictionMap = merge(statesMap, predictionDataFrame, by = "region")
# Lastly, we need to make sure the observations are in order so that the map
# is drawn properly:
predictionMap = predictionMap[order(predictionMap$order),]
str(predictionMap)
str(statesMap)
# 2.4
# color the states according to our binary predictions
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPredictionBinary))+
geom_polygon(color = "black")
# 2.5
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPredictionBinary))+
geom_polygon(color = "black") +
scale_fill_gradient(low = "blue", high = "red", guide = "legend", breaks= c(0,1), labels = c("Democrat", "Republican"), name = "Prediction 2012")
# plot the probabilities instead of the binary predictions
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPrediction))+
geom_polygon(color = "black") +
scale_fill_gradient(low = "blue", high = "red", guide = "legend", breaks= c(0,1), labels = c("Democrat", "Republican"), name = "Prediction 2012")
## 3.UNDERSTANDING THE PREDICTIONS
# 3.2
# What was our predicted probability for the state of Florida?
predictionDataFrame # look at row containing Florida
