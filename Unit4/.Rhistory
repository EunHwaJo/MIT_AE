library(swirl)
swirl()
var(rpois(1000),50)
var(rpois(1000,50))
source('~/.active-rstudio-document', echo=TRUE)
stevens = read.csv("./data/stevens.csv")
str(stevens)
stevens = read.csv("./data/stevens.csv")
str(stevens)
# Split the data
library(caTools)
set.seed(3000)
spl = sample.split(stevens$Reverse, SplitRatio = 0.7)
Train = subset(stevens, spl==TRUE)
Test = subset(stevens, spl==FALSE)
# Install rpart library
install.packages("rpart")
library(rpart)
install.packages("rpart.plot")
library(rpart.plot)
install.packages("rpart")
install.packages("rpart")
# VIDEO 4
# Read in the data
stevens = read.csv("./data/stevens.csv")
str(stevens)
# Split the data
library(caTools)
set.seed(3000)
spl = sample.split(stevens$Reverse, SplitRatio = 0.7)
Train = subset(stevens, spl==TRUE)
Test = subset(stevens, spl==FALSE)
# Install rpart library
#install.packages("rpart")
library(rpart)
#install.packages("rpart.plot")
library(rpart.plot)
StevensTree = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, method="class", minbucket=25)
prp(StevensTree)
tevens = read.csv("./data/stevens.csv")
str(stevens)
# Split the data
library(caTools)
set.seed(3000)
spl = sample.split(stevens$Reverse, SplitRatio = 0.7)
Train = subset(stevens, spl==TRUE)
Test = subset(stevens, spl==FALSE)
# Install rpart library
#install.packages("rpart")
library(rpart)
#install.packages("rpart.plot")
library(rpart.plot)
# CART model
StevensTree = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, method="class", minbucket=25)
prp(StevensTree)
# Make predictions
PredictCART = predict(StevensTree, newdata = Test, type = "class")
table(Test$Reverse, PredictCART)
(41+71)/(41+36+22+71)
# ROC curve
library(ROCR)
PredictROC = predict(StevensTree, newdata = Test)
PredictROC
pred = prediction(PredictROC[,2], Test$Reverse)
perf = performance(pred, "tpr", "fpr")
plot(perf)
as.numeric(performance(pred, "auc")@y.values)
# CART model
StevensTree = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, method="class", minbucket=5)
prp(StevensTree)
# Make predictions
PredictCART = predict(StevensTree, newdata = Test, type = "class")
table(Test$Reverse, PredictCART)
(41+71)/(41+36+22+71)
# ROC curve
library(ROCR)
PredictROC = predict(StevensTree, newdata = Test)
PredictROC
pred = prediction(PredictROC[,2], Test$Reverse)
perf = performance(pred, "tpr", "fpr")
plot(perf)
as.numeric(performance(pred, "auc")@y.values)
# VIDEO 5 - Random Forests
# Install randomForest package
install.packages("randomForest")
library(randomForest)
# Build random forest model
StevensForest = randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, ntree=200, nodesize=25 )
# Convert outcome to factor
Train$Reverse = as.factor(Train$Reverse)
Test$Reverse = as.factor(Test$Reverse)
# Try again
StevensForest = randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, ntree=200, nodesize=25 )
# Make predictions
PredictForest = predict(StevensForest, newdata = Test)
table(Test$Reverse, PredictForest)
(40+74)/(40+37+19+74)
# VIDEO 6
# Install cross-validation packages
install.packages("caret")
library(caret)
install.packages("e1071")
library(e1071)
# Define cross-validation experiment
numFolds = trainControl( method = "cv", number = 10 )
cpGrid = expand.grid( .cp = seq(0.01,0.5,0.01))
# Perform the cross validation
train(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, method = "rpart", trControl = numFolds, tuneGrid = cpGrid )
# Create a new CART model
StevensTreeCV = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, method="class", cp = 0.18)
# Make predictions
PredictCV = predict(StevensTreeCV, newdata = Test, type = "class")
table(Test$Reverse, PredictCV)
(59+64)/(59+18+29+64)
# Read in the data
stevens = read.csv("./data/stevens.csv")
str(stevens)
# Split the data
library(caTools)
set.seed(3000)
spl = sample.split(stevens$Reverse, SplitRatio = 0.7)
Train = subset(stevens, spl==TRUE)
Test = subset(stevens, spl==FALSE)
# Install rpart library
#install.packages("rpart")
library(rpart)
#install.packages("rpart.plot")
library(rpart.plot)
# CART model
StevensTree = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, method="class", minbucket=5)
prp(StevensTree)
# Make predictions
PredictCART = predict(StevensTree, newdata = Test, type = "class")
table(Test$Reverse, PredictCART)
(41+71)/(41+36+22+71)
# ROC curve
library(ROCR)
PredictROC = predict(StevensTree, newdata = Test)
PredictROC
pred = prediction(PredictROC[,2], Test$Reverse)
perf = performance(pred, "tpr", "fpr")
plot(perf)
as.numeric(performance(pred, "auc")@y.values)
# CART model
StevensTree = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, method="class", minbucket=100)
prp(StevensTree)
# Make predictions
PredictCART = predict(StevensTree, newdata = Test, type = "class")
table(Test$Reverse, PredictCART)
(41+71)/(41+36+22+71)
# ROC curve
library(ROCR)
PredictROC = predict(StevensTree, newdata = Test)
PredictROC
pred = prediction(PredictROC[,2], Test$Reverse)
perf = performance(pred, "tpr", "fpr")
plot(perf)
as.numeric(performance(pred, "auc")@y.values)
install.packages("randomForest")
library(randomForest)
library(randomForest)
StevensForest = randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, ntree=200, nodesize=25 )
# Convert outcome to factor
Train$Reverse = as.factor(Train$Reverse)
Test$Reverse = as.factor(Test$Reverse)
# Try again
StevensForest = randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, ntree=200, nodesize=25 )
# Make predictions
PredictForest = predict(StevensForest, newdata = Test)
table(Test$Reverse, PredictForest)
PredictForest = predict(StevensForest, newdata = Test)
table(Test$Reverse, PredictForest)
set.seed(100)
StevensForest = randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, ntree=200, nodesize=25 )
# Make predictions
PredictForest = predict(StevensForest, newdata = Test)
table(Test$Reverse, PredictForest)
(41+75)/(41+36+18+75)
PredictForest = predict(StevensForest, newdata = Test)
ctab<-table(Test$Reverse, PredictForest)
(40+74)/(40+37+19+74)
accuracy<-(ctab[1,1]+ctab[2,2])/sum(ctab)
accuracy<-(ctab[1,1]+ctab[2,2])/sum(ctab)
accuracy
PredictForest = predict(StevensForest, newdata = Test)
ctab<-table(Test$Reverse, PredictForest)
#(40+74)/(40+37+19+74)
ctab
accuracy<-(ctab[1,1]+ctab[2,2])/sum(ctab)
accuracy
set.seed(200)
StevensForest = randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, ntree=200, nodesize=25 )
# Make predictions
PredictForest = predict(StevensForest, newdata = Test)
ctab<-table(Test$Reverse, PredictForest)
#(40+74)/(40+37+19+74)
ctab
accuracy<-(ctab[1,1]+ctab[2,2])/sum(ctab)
accuracy
library(caret)
library(e1071)
numFolds = trainControl( method = "cv", number = 10 )
cpGrid = expand.grid( .cp = seq(0.01,0.5,0.01))
# Perform the cross validation
train(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, method = "rpart", trControl = numFolds, tuneGrid = cpGrid )
# Create a new CART model
StevensTreeCV = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, method="class", cp = 0.18)
# Make predictions
PredictCV = predict(StevensTreeCV, newdata = Test, type = "class")
table(Test$Reverse, PredictCV)
(59+64)/(59+18+29+64)
PredictCV = predict(StevensTreeCV, newdata = Test, type = "class")
cvtab<-table(Test$Reverse, PredictCV)
cvtab
cvaccuracy<-(cvtab[1,1]+cvtab[2,2])/sum(cvtab)
cvaccuracy
PredictROC = predict(StevensTreeCV, newdata = Test)
PredictROC
pred = prediction(PredictROC[,2], Test$Reverse)
perf = performance(pred, "tpr", "fpr")
plot(perf)
PredictROC = predict(StevensTreeCV, newdata = Test)
PredictROC
pred = prediction(PredictROC[,2], Test$Reverse)
perf = performance(pred, "tpr", "fpr")
plot(perf)
stevens = read.csv("./data/stevens.csv")
str(stevens)
# Split the data
library(caTools)
set.seed(3000)
spl = sample.split(stevens$Reverse, SplitRatio = 0.7)
Train = subset(stevens, spl==TRUE)
Test = subset(stevens, spl==FALSE)
# Install rpart library
#install.packages("rpart")
library(rpart)
#install.packages("rpart.plot")
library(rpart.plot)
# CART model
StevensTree = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, method="class", minbucket=100)
prp(StevensTree)
# Make predictions
PredictCART = predict(StevensTree, newdata = Test, type = "class")
table(Test$Reverse, PredictCART)
(41+71)/(41+36+22+71)
# ROC curve
library(ROCR)
PredictROC = predict(StevensTree, newdata = Test)
PredictROC
pred = prediction(PredictROC[,2], Test$Reverse)
perf = performance(pred, "tpr", "fpr")
plot(perf)
# Install randomForest package
#install.packages("randomForest")
library(randomForest)
# Build random forest model
StevensForest = randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, ntree=200, nodesize=25 )
# Convert outcome to factor
Train$Reverse = as.factor(Train$Reverse)
Test$Reverse = as.factor(Test$Reverse)
# Try again
set.seed(200)
StevensForest = randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, ntree=200, nodesize=25 )
# Make predictions
PredictForest = predict(StevensForest, newdata = Test)
ctab<-table(Test$Reverse, PredictForest)
#(40+74)/(40+37+19+74)
ctab
accuracy<-(ctab[1,1]+ctab[2,2])/sum(ctab)
accuracy
# Install cross-validation packages
#install.packages("caret")
library(caret)
#install.packages("e1071")
library(e1071)
# Define cross-validation experiment
numFolds = trainControl( method = "cv", number = 10 )
cpGrid = expand.grid( .cp = seq(0.01,0.5,0.01))
# Perform the cross validation
train(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, method = "rpart", trControl = numFolds, tuneGrid = cpGrid )
# Create a new CART model
StevensTreeCV = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, method="class", cp = 0.18)
# Make predictions
PredictCV = predict(StevensTreeCV, newdata = Test, type = "class")
cvtab<-table(Test$Reverse, PredictCV)
cvtab
cvaccuracy<-(cvtab[1,1]+cvtab[2,2])/sum(cvtab)
cvaccuracy
(59+64)/(59+18+29+64)
PredictROC = predict(StevensTreeCV, newdata = Test)
PredictROC
pred = prediction(PredictROC[,2], Test$Reverse)
perf = performance(pred, "tpr", "fpr")
plot(perf)
prp(StevensTree)
StevensTreeCV = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, method="class", cp = 0.18)
prp(StevensTreeCV)
StevensTreeCV = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, method="class", cp = 0.18)
prp(StevensTreeCV)
x <- -5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
plot(x,y)
knot0=0
splineTerms <- sapply(knot0, function(knot) (x > knot) * (x - knot))
xMat <- cbind(1, x, splineTerms)
yhat <- predict(lm(y ~ xMat - 1))
plot(x, y, frame = FALSE, pch = 21, bg = "lightblue", cex = 2)
lines(x, yhat, col = "red", lwd = 2)
(yhat[11]-yhat[6])/(x[11]-x[6])
splineTerms
lm(y ~ xMat - 1)
fit<-lm(y ~ xMat - 1)
summary(fit)
set.seed(1234)
pdf_var         <- 25
iterations      <- 10000
samplesize      <- 1000
mean_set_size   <- 5
xbreaks         <- 40
scaling         <- (mean_set_size-1)*(samplesize)/pdf_var
message ("Various parent distributions with variance = ", pdf_var,", sample size = ",
samplesize, " and iterations = ", iterations)
message ("Variances of means sample size = ", mean_set_size,", implies chisq dof = ", mean_set_size-1)
Distributions    <- function(mns, mean, sd, scaling, mean_set_size, iterations, xbreaks) {
## Plot means distribution
hist(mns, breaks = xbreaks, col = "lightblue", prob = TRUE,
main = "Means of random sample sets", xlab = "Value",
ylab = "Sample mean probability", cex.axis = 0.5, cex.lab = 0.6, cex.main = 0.7)
curve(dnorm(x, mean = mean, sd = sd), add = TRUE, yaxt = "n", lwd=2)
## Calculate and plot variances of means distribution histogram
vars        <- NULL
for (i in 1:(iterations)){vars    <- c(vars, var(sample(mns, mean_set_size, replace = TRUE)))}
hist(vars, breaks = xbreaks, col = "lightblue", prob = TRUE,
main = "Variances of random means of random sample sets", xlab = "Value",
ylab = "Sample variance probability", cex.axis = 0.5, cex.lab = 0.6, cex.main = 0.7)
curve(scaling*dchisq(x*scaling, df = (mean_set_size-1)), add = TRUE, yaxt = "n", lwd=2)
## Finally do a Q-Q plot for the variances against a chi-sqr distribution
qqplot(vars, qchisq(ppoints(vars), df = mean_set_size-1), pch=".", main = "Chisq against variance QQ plot",
xlab = "Variance", ylab = "Chisq", cex.axis = 0.5, cex.lab = 0.6, cex.main = 0.7)
return(NULL)
}
qt(.95,9)
qt(c(0.95,0.975),9)
qt(c(0.95,0.975,.005),9)
qt(c(0.95,0.975,.995),9)
qt(c(0.95,0.975,.98),9)
qt(c(0.95,0.975,.01),9)
qt(.9,9,lower.tail=FALSE)
qt(.9,9)
# Read in the data
Claims = read.csv("ClaimsData.csv")
str(Claims)
# Percentage of patients in each cost bucket
table(Claims$bucket2009)/nrow(Claims)
# Split the data
library(caTools)
set.seed(88)
spl = sample.split(Claims$bucket2009, SplitRatio = 0.6)
ClaimsTrain = subset(Claims, spl==TRUE)
ClaimsTest = subset(Claims, spl==FALSE)
setwd("C:/Users/Mike/Rspace/MIT_AE/Unit4")
# Unit 4 - "Keeping an Eye on Healthcare Costs" Lecture
# VIDEO 6
# Read in the data
Claims = read.csv("./data/ClaimsData.csv")
str(Claims)
# Percentage of patients in each cost bucket
table(Claims$bucket2009)/nrow(Claims)
# Split the data
library(caTools)
set.seed(88)
spl = sample.split(Claims$bucket2009, SplitRatio = 0.6)
ClaimsTrain = subset(Claims, spl==TRUE)
ClaimsTest = subset(Claims, spl==FALSE)
# Unit 4 - "Keeping an Eye on Healthcare Costs" Lecture
# VIDEO 6
# Read in the data
Claims = read.csv("./data/ClaimsData.csv")
str(Claims)
# Percentage of patients in each cost bucket
table(Claims$bucket2009)/nrow(Claims)
# Split the data
library(caTools)
set.seed(88)
spl = sample.split(Claims$bucket2009, SplitRatio = 0.6)
ClaimsTrain = subset(Claims, spl==TRUE)
ClaimsTest = subset(Claims, spl==FALSE)
mean(ClaimsTrain$age)
count(ClaimsTrain$diabetes>0)
sum(ClaimsTrain$diabetes>0)
sum(ClaimsTrain$diabetes>0)/nrow(ClaimsTrain)
table(ClaimsTest$bucket2009, ClaimsTest$bucket2008)
table(ClaimsTest$bucket2009, seq(1,1:nrow(ClaimsTest)))
?seq
table(ClaimsTest$bucket2009, seq(1:nrow(ClaimsTest)))
table(ClaimsTest$bucket2009, nrow(ClaimsTest))
ClaimsTest$CB1=1
table(ClaimsTest$bucket2009, ClaimsTest$CB1)
ct[1]/nrow(ClaimsTest)
ClaimsTest$CB1=1
ct<-table(ClaimsTest$bucket2009, ClaimsTest$CB1)
#accuracy
ct[1]/nrow(ClaimsTest)
ClaimsTest$CB1=1
ct<-table(ClaimsTest$bucket2009, ClaimsTest$CB1)
#accuracy
ct[1]/nrow(ClaimsTest)
#penalty
as.matrix(table(ClaimsTest$bucket2009, ClaimsTest$CB1))*PenaltyMatrix
sum(as.matrix(table(ClaimsTest$bucket2009, ClaimsTest$CB1))*PenaltyMatrix)/nrow(ClaimsTest)
Claims = read.csv("./data/ClaimsData.csv")
str(Claims)
# Percentage of patients in each cost bucket
table(Claims$bucket2009)/nrow(Claims)
# Split the data
library(caTools)
set.seed(88)
spl = sample.split(Claims$bucket2009, SplitRatio = 0.6)
ClaimsTrain = subset(Claims, spl==TRUE)
ClaimsTest = subset(Claims, spl==FALSE)
#qq
#What is the average age of patients in the training set, ClaimsTrain?
mean(ClaimsTrain$age)
#What proportion of people in the training set (ClaimsTrain) had at least
#one diagnosis code for diabetes?
sum(ClaimsTrain$diabetes>0)/nrow(ClaimsTrain)
# VIDEO 7
# Baseline method
table(ClaimsTest$bucket2009, ClaimsTest$bucket2008)
(110138 + 10721 + 2774 + 1539 + 104)/nrow(ClaimsTest)
# Penalty Matrix
PenaltyMatrix = matrix(c(0,1,2,3,4,2,0,1,2,3,4,2,0,1,2,6,4,2,0,1,8,6,4,2,0), byrow=TRUE, nrow=5)
PenaltyMatrix
# Penalty Error of Baseline Method
as.matrix(table(ClaimsTest$bucket2009, ClaimsTest$bucket2008))*PenaltyMatrix
sum(as.matrix(table(ClaimsTest$bucket2009, ClaimsTest$bucket2008))*PenaltyMatrix)/nrow(ClaimsTest)
#qq
ClaimsTest$CB1=1
ct<-table(ClaimsTest$bucket2009, ClaimsTest$CB1)
#accuracy
ct[1]/nrow(ClaimsTest)
#penalty
as.matrix(table(ClaimsTest$bucket2009, ClaimsTest$CB1))*PenaltyMatrix
sum(as.matrix(table(ClaimsTest$bucket2009, ClaimsTest$CB1))*PenaltyMatrix)/nrow(ClaimsTest)
dim(table(ClaimsTest$bucket2009, ClaimsTest$CB1))
table(ClaimsTest$bucket2009, ClaimsTest$CB1)*PenaltyMatrix[,1]
sum(table(ClaimsTest$bucket2009, ClaimsTest$CB1)*PenaltyMatrix[,1])/nrow(ClaimsTest)
sum(table(ClaimsTest$bucket2009, ClaimsTest$CB1)*PenaltyMatrix[,1])#/nrow(ClaimsTest)
sum(table(ClaimsTest$bucket2009, ClaimsTest$CB1)*PenaltyMatrix[,1])/nrow(ClaimsTest)
library(rpart)
library(rpart.plot)
# CART model
ClaimsTree = rpart(bucket2009 ~ age + alzheimers + arthritis + cancer + copd + depression + diabetes + heart.failure + ihd + kidney + osteoporosis + stroke + bucket2008 + reimbursement2008, data=ClaimsTrain, method="class", cp=0.00005)
prp(ClaimsTree)
# Make predictions
PredictTest = predict(ClaimsTree, newdata = ClaimsTest, type = "class")
table(ClaimsTest$bucket2009, PredictTest)
(114141 + 16102 + 118 + 201 + 0)/nrow(ClaimsTest)
# Penalty Error
as.matrix(table(ClaimsTest$bucket2009, PredictTest))*PenaltyMatrix
sum(as.matrix(table(ClaimsTest$bucket2009, PredictTest))*PenaltyMatrix)/nrow(ClaimsTest)
# New CART model with loss matrix
ClaimsTree = rpart(bucket2009 ~ age + alzheimers + arthritis + cancer + copd + depression + diabetes + heart.failure + ihd + kidney + osteoporosis + stroke + bucket2008 + reimbursement2008, data=ClaimsTrain, method="class", cp=0.00005, parms=list(loss=PenaltyMatrix))
# Redo predictions and penalty error
PredictTest = predict(ClaimsTree, newdata = ClaimsTest, type = "class")
table(ClaimsTest$bucket2009, PredictTest)
(94310 + 18942 + 4692 + 636 + 2)/nrow(ClaimsTest)
sum(as.matrix(table(ClaimsTest$bucket2009, PredictTest))*PenaltyMatrix)/nrow(ClaimsTest)
# VIDEO 8
# Load necessary libraries
library(rpart)
library(rpart.plot)
# CART model
ClaimsTree = rpart(bucket2009 ~ age + alzheimers + arthritis + cancer + copd + depression + diabetes + heart.failure + ihd + kidney + osteoporosis + stroke + bucket2008 + reimbursement2008, data=ClaimsTrain, method="class", cp=0.00005)
prp(ClaimsTree)
# Make predictions
PredictTest = predict(ClaimsTree, newdata = ClaimsTest, type = "class")
table(ClaimsTest$bucket2009, PredictTest)
(114141 + 16102 + 118 + 201 + 0)/nrow(ClaimsTest)
# Penalty Error
as.matrix(table(ClaimsTest$bucket2009, PredictTest))*PenaltyMatrix
sum(as.matrix(table(ClaimsTest$bucket2009, PredictTest))*PenaltyMatrix)/nrow(ClaimsTest)
# New CART model with loss matrix
ClaimsTree = rpart(bucket2009 ~ age + alzheimers + arthritis + cancer + copd + depression + diabetes + heart.failure + ihd + kidney + osteoporosis + stroke + bucket2008 + reimbursement2008, data=ClaimsTrain, method="class", cp=0.00005, parms=list(loss=PenaltyMatrix))
# Redo predictions and penalty error
PredictTest = predict(ClaimsTree, newdata = ClaimsTest, type = "class")
table(ClaimsTest$bucket2009, PredictTest)
(94310 + 18942 + 4692 + 636 + 2)/nrow(ClaimsTest)
sum(as.matrix(table(ClaimsTest$bucket2009, PredictTest))*PenaltyMatrix)/nrow(ClaimsTest)
ClaimsTree = rpart(bucket2009 ~ age + alzheimers + arthritis + cancer + copd + depression + diabetes + heart.failure + ihd + kidney + osteoporosis + stroke + bucket2008 + reimbursement2008, data=ClaimsTrain, method="class", cp=0.00005, parms=list(loss=PenaltyMatrix))
# Redo predictions and penalty error
PredictTest = predict(ClaimsTree, newdata = ClaimsTest, type = "class")
table(ClaimsTest$bucket2009, PredictTest)
(94310 + 18942 + 4692 + 636 + 2)/nrow(ClaimsTest)
sum(as.matrix(table(ClaimsTest$bucket2009, PredictTest))*PenaltyMatrix)/nrow(ClaimsTest)
# Read in data
boston = read.csv(",/data/boston.csv")
str(boston)
# Plot observations
plot(boston$LON, boston$LAT)
# VIDEO 2
# Read in data
boston = read.csv("./data/boston.csv")
str(boston)
# Plot observations
plot(boston$LON, boston$LAT)
points(boston$LON[boston$TRACT==3531],boston$LAT[boston$TRACT==3531],col="red", pch=20)
